# -*- coding: utf-8 -*-
"""Breast_cancer_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/168TkH_ks_QXLyY9LkleD0YLBDA8ksgpr

#ML Project: Breast Cancer Detection Using Machine Learning Classifiers

Breast cancer continues to be one of the most prevalent and challenging health issues worldwide, especially among women. Early and accurate diagnosis plays a critical role in determining the course of treatment and significantly improving survival rates. Distinguishing between malignant (cancerous) and benign (non-cancerous) tumors at an early stage can lead to timely intervention and better patient outcomes.

> The primary goal of this project is to explore, compare, and implement different machine learning classification algorithms to build an effective predictive model.

**Table of Content**

1. Project Overview
2. Datset loading and features exploration
3. Data Exploration (EDA / Exploratory Data Analysis)
4. Data Preprocessing
5. Training using different models
6. Evaluation of different models
7. Saving the trained model
8. Conclusion

##1. Project Overview

We will be appling different machine learning algorithms to classify breast tumors as malignant or benign based on clinical and genetic features available from patients. We will be utilizing the well-established `load_breast_cancer` dataset from Scikit-learn, which contains real-world medical data.


The Breast Cancer Wisconsin (Diagnostic) dataset can be downloaded from: https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic

For this project, we will use python libaries such as numpy, pandas, matplotlib and seaborn for various task such as analsying and visualization of data.
"""

# import libraries
import pandas as pd # for data manupulation or analysis
import numpy as np # for numeric calculation
import matplotlib.pyplot as plt # for data visualization
import seaborn as sns # for data visualization

"""#2. Datset loading and features exploration


> The [Breast_cancer Wisconsin (Diagnostic)](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic) dataset is a well - strututred datset with 30 features derived from digitized images of breast mass samples, capturing key characteristics like radius, texture, and compactness of cell nuclei.


"""

#Load breast cancer dataset
from sklearn.datasets import load_breast_cancer
cancer_dataset = load_breast_cancer()

# keys in dataset
cancer_dataset.keys()

"""2. B. Feature Description

The UCI ML Breast Cancer Wisconsin (Diagnostic) dataset is a widely used dataset in machine learning for binary classification tasks. It contains features computed from digitized images of fine needle aspirates (FNA) of breast masses, describing characteristics of the cell nuclei present in the images. The dataset is used to predict whether a breast mass is benign (B) or malignant (M).

Dataset Features:
The dataset consists of 569 instances (samples) and 32 attributes (columns) per instance. The features include:

1. ID Number – A unique identifier for each sample.

2. Diagnosis (Target Variable) – Binary classification label:

M (Malignant) – Indicates cancerous tumor.

B (Benign) – Indicates non-cancerous tumor.

Ten Real-Valued Features Computed for Each Cell Nucleus:
For each of the following features, the dataset provides the mean, standard error (SE), and worst (largest) value, resulting in 30 numerical features in total.

1. Radius – Mean distance from the center to points on the perimeter.

2. Texture – Standard deviation of gray-scale values.

3. Perimeter – Total length of the boundary of the nucleus.

4. Area – The area of the nucleus.

5. Smoothness – Local variation in radius lengths.

6. Compactness – Calculated as (Perimeter² / Area - 1.0).

7. Concavity – Severity of concave portions of the contour.

8. Concave Points – Number of concave portions of the contour.

9. Symmetry – How similar the nucleus is when mirrored.

10. Fractal Dimension – "Coastline approximation" (complexity of the boundary).
"""

print(cancer_dataset.DESCR)

print(cancer_dataset['feature_names'])

#now to split the data, we create datafreame for easy visualization
cancer_df = pd.DataFrame(cancer_dataset['data'], columns=cancer_dataset['feature_names'])
cancer_df['target'] = cancer_dataset['target']

cancer_df.head()

cancer_df.target.head()

"""#3. Data Exploration (EDA / Exploratory Data Analysis)

The goal here is to find out more about the data and become a subject matter expert on the dataset that you're working with. This is because if someone asks a question, we can answer them, and also assess whether our model is overfitting or underfitting and work accordingly.

There is no set procedure for EDA. So we'll go with this small checklist for ourselves:

What question(s) are you trying to solve?
What kind of data do we have and how do we treat different types?
What is missing from the data and how do you deal with it?
Where are the outliers and why should you care about them?
How can you add, change or remove features to get more out of your data?
"""

cancer_features = cancer_df[cancer_dataset['feature_names']].head()

cancer_df.info()

cancer_features

"""#Data Visualization

Here, we observed some patterns that will help us to the data for further cleaning.



> Class Separation

In the pairplot, certain features like mean radius, mean perimeter, and mean area show clear separation between malignant and benign tumors, indicating they are strong predictors for classification and should be observed carefully.

> Feature Correlation

Several features are highly correlated with each other, such as mean radius, mean perimeter, and mean area, suggesting redundancy. This is beacuse they are mathemateically dependent and tus do not provide independent information—they are redundant. This indicates that dimensionality reduction techniques like PCA can be beneficial. For example: Instead of using mean radius, mean perimeter, and mean area, PCA might create one component (e.g., "Tumor Size") capturing most of their variance.



> Distribution Differences

Features like mean texture and worst smoothness have overlapping distributions across classes, meaning they might contribute less individually to model performance compared to other more separable features.

> Outliers and Spread

 few outliers are visible in the scatterplots for features like area error and concavity error, which could affect model robustness and might need to be treated or analyzed separately.



> Feature Scaling

Since the feature scales vary widely (some features have much larger ranges than others), applying standardization (like StandardScaler) is necessary before fitting models.

The pair plot is used to show the numeric distribution in the scatter plot.
"""

# Paiplot of cancer dataframe
sns.pairplot(cancer_df, hue = 'target')

"""Inference from these graphs:

Overall, the breast cancer dataset highlights the importance of careful feature selection, handling multicollinearity, and applying feature scaling.
Proper preprocessing, combined with the choice of informative features, can significantly enhance the performance of classification models in predicting tumor malignancy.
"""

# pair plot of sample feature
sns.pairplot(cancer_df, hue = 'target',
             vars = ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness'] )

"""The pair plot showing malignant and benign tumor data distributed in two classes. It is easy to differentiate in the pair plot.

The bar graph shows the distribution of target class in our dataset. From this, we can infer that we have more data for malignant cases as compared to benign
"""

sns.countplot(x=cancer_df.target)

"""Heatmap of a correlation matrix

> To find a correlation between each feature and target we visualize heatmap using the correlation matrix


"""

# Heatmap of Correlation matrix of breast cancer DataFrame
plt.figure(figsize=(20,20))
sns.heatmap(cancer_df.corr(), annot = True, cmap ='coolwarm', linewidths=2)

"""From this heatmap we can infer some points sucha as:



> Strong Positive Correlations:

Features like mean radius, mean perimeter, and mean area are highly positively correlated (correlation coefficient close to 1.0), indicating strong redundancy among them.



> Target Correlation:
The target variable (malignant/benign) shows negative correlations with features like mean radius, mean area, and worst perimeter, suggesting that larger tumor sizes are associated with malignancy[1] than being benign[0].



> Low or Weak Correlations

Features such as fractal dimension error and symmetry error exhibit very weak correlations with both other features and the target, indicating they might be less informative.

Correlation barplot


> This will give a clear, ranked view of which features are most correlated (positively or negatively) with the target. So you can easily spot the most important features.

So, we create a new datsframe for easy handling of the data where we will only have features. We have 569 rows with 30 features in the new dataframe
"""

# create second DataFrame by droping target
cancer_df2 = cancer_df.drop(['target'], axis = 1)
print("The shape of 'cancer_df2' is : ", cancer_df2.shape)

"""Correlation barplot


Taking the correlation of each feature with the target and the visualize barplot.
"""

# visualize correlation barplot
plt.figure(figsize=(16, 5))

# Calculate correlations once to avoid redundant computation
correlations = cancer_df2.corrwith(cancer_df['target'])

# Create bar plot with improved styling
ax = sns.barplot(
    x=correlations.index,
    y=correlations.values,
    palette="flare"  # Adds a color gradient for better visual distinction
)

# Rotate x-axis labels for readability
ax.set_xticklabels(ax.get_xticklabels(), rotation=90, ha='center')

ax.set_title("Feature Correlations with Target (Benign/Malignant)", pad=20)
ax.set_xlabel("Features")
ax.set_ylabel("Correlation Coefficient")
plt.tight_layout()
plt.show()

"""This clean bar plot showing which features are most strongly correlated (positively/negatively) with tumor malignancy.

Example:

smoothness error (high strongly positively correlation).

mean factor dimension, texture error, and symmetry error (less positively coorelated)

others remaining (strongly negatively correlated)

##Data Preprocessing

We have already checked that we dont have any nullvalue and this we will go ahead and split the DataFrame in train and test
"""

X = cancer_df.drop(['target'], axis = 1)
X.head(6)

y = cancer_df['target']
y.head(6)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state= 42, stratify=y)

"""Feature Scaling

Now since we have different data in variable range we would have to normalize the data. We will do this using  scikit learn standardscaler.

"""

# Feature scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train_sc = sc.fit_transform(X_train)
X_test_sc = sc.transform(X_test)

"""##**Breast Cancer Detection Machine Learning Model Building**

Since, our data was already clean and did not conatin any null-values either, we can directly proceed to fit different ML models.

We have to find the best Machine learning algorithm revelant for our data and problem. Since, the output is categorical, we will use different supervised classification machine learning algorithms.

To build the best model, we have to train and test the dataset with multiple Machine Learning algorithms then we can find the best ML model. So let’s try, different ML algorithms one by one and compare their accurary.
"""

from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

"""Logistic Regression


> Here, the scaled data is giving us more accuracy then the unscaled data.
So, the highest accuracy we could achieve from logistic regression is 98.2%
"""

from sklearn import linear_model
from sklearn.linear_model import LogisticRegression


lr_classifier = LogisticRegression(max_iter=10000, random_state=42)
lr_classifier.fit(X_train, y_train)
y_pred_lr = lr_classifier.predict(X_test)

accuracy_score(y_test, y_pred_lr)*100

# Lets's try training the model with standared scaled data
lr_classifier2 = LogisticRegression(max_iter=10000, random_state = 42)
lr_classifier2.fit(X_train_sc, y_train)
y_pred_lr_sc = lr_classifier2.predict(X_test_sc)

accuracy_score(y_test, y_pred_lr_sc)*100

"""Support Vector Classifier

> Here, the scaled data is again giving us more accuracy then the unscaled data.
So, the accururacy we could achiene from SVM is 98.2%
"""



from sklearn.svm import SVC
svc_classifier = SVC()
svc_classifier.fit(X_train, y_train)
y_pred_scv = svc_classifier.predict(X_test)
accuracy_score(y_test, y_pred_scv)

# Train with Standard scaled Data
svc_classifier2 = SVC()
svc_classifier2.fit(X_train_sc, y_train)
y_pred_svc_sc = svc_classifier2.predict(X_test_sc)
accuracy_score(y_test, y_pred_svc_sc)

"""K – Nearest Neighbor Classifier

> Here, the scaled data is giving us equal accuracy as the unscaled data.
So, the accururacy we could achiene from KNN is 95.61%
"""

from sklearn.neighbors import KNeighborsClassifier
knn_classifier = KNeighborsClassifier(n_neighbors = 5)
knn_classifier.fit(X_train, y_train)
y_pred_knn = knn_classifier.predict(X_test)
accuracy_score(y_test, y_pred_knn)

# Train with Standard scaled Data
knn_classifier2 = KNeighborsClassifier(n_neighbors = 5)
knn_classifier2.fit(X_train_sc, y_train)
y_pred_knn_sc = knn_classifier2.predict(X_test_sc)
accuracy_score(y_test, y_pred_knn_sc)

"""Decision Tree Classifier


> Here, the scaled data is giving us more accuracy then the unscaled data.
So, the highest accuracy we could achieve from Decision Tree Classifiern is 94.7%


"""

from sklearn.tree import DecisionTreeClassifier
dt_classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 42)
dt_classifier.fit(X_train, y_train)
y_pred_dt = dt_classifier.predict(X_test)
accuracy_score(y_test, y_pred_dt)

"""We can always try training the model again with scaled data"""

# Train with Standard scaled Data
dt_classifier2 = DecisionTreeClassifier(criterion = 'entropy', random_state = 42)
dt_classifier2.fit(X_train_sc, y_train)
y_pred_dt_sc = dt_classifier.predict(X_test_sc)
accuracy_score(y_test, y_pred_dt_sc)

"""Random Forest Classifier


> Here, the maximum accuruary we could get from random forest is 96.4%
"""

# Random Forest Classifier
from sklearn.ensemble import RandomForestClassifier
rf_classifier = RandomForestClassifier(n_estimators = 20, criterion = 'entropy', random_state = 51)
rf_classifier.fit(X_train, y_train)
y_pred_rf = rf_classifier.predict(X_test)
accuracy_score(y_test, y_pred_rf)

rf_classifier2 = RandomForestClassifier(n_estimators = 20, criterion = 'entropy', random_state = 51)
rf_classifier2.fit(X_train_sc, y_train)
y_pred_rf2 = rf_classifier2.predict(X_test_sc)
accuracy_score(y_test, y_pred_rf2)

"""XGBoost Classifier"""

# XGBoost Classifier
from xgboost import XGBClassifier
xgb_classifier = XGBClassifier()
xgb_classifier.fit(X_train, y_train)
y_pred_xgb = xgb_classifier.predict(X_test)
accuracy_score(y_test, y_pred_xgb)

# Train with Standard scaled Data
xgb_classifier2 = XGBClassifier()
xgb_classifier2.fit(X_train_sc, y_train)
y_pred_xgb_sc = xgb_classifier2.predict(X_test_sc)
accuracy_score(y_test, y_pred_xgb_sc)

"""Hypertuning the XGBoost model"""

# Manually giving different parameters for XGBoost classifier
params={
 "learning_rate"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,
 "max_depth"        : [ 3, 4, 5, 6, 8, 10, 12, 15],
 "min_child_weight" : [ 1, 3, 5, 7 ],
 "gamma"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],
 "colsample_bytree" : [ 0.3, 0.4, 0.5 , 0.7 ]
}

# Randomized Search using import
from sklearn.model_selection import RandomizedSearchCV
random_search = RandomizedSearchCV(xgb_classifier, param_distributions=params, scoring= 'accuracy', n_jobs= -1, verbose= 3)
random_search.fit(X_train, y_train)

print('Best score: ', random_search.best_score_)
print('Best parameters: ', random_search.best_params_)
print('Best estimator: ', random_search.best_estimator_)

# Train the XGBoost model with the best parameters found by RandomizedSearchCV
best_xgb_classifier = random_search.best_params_
best_xgb_classifier = random_search.best_estimator_
best_xgb_classifier.fit(X_train, y_train)

# Make predictions ahain on the test set using the best model
y_pred_best_xgb = best_xgb_classifier.predict(X_test)

# Evaluate the best model
accuracy_best_xgb = accuracy_score(y_test, y_pred_best_xgb)
print(f"Accuracy of the best XGBoost model: {accuracy_best_xgb}")

cm = confusion_matrix(y_test, y_pred_best_xgb)
plt.title('Heatmap of Confusion Matrix', fontsize = 15)
sns.heatmap(cm, annot = True)
plt.show()

"""The model is giving every less type I and type II error which is very good.

Classification Report of best model i.e. XGBoost
"""

print(classification_report(y_test, y_pred_best_xgb))

"""Cross-validation of the ML model"""

from sklearn.model_selection import cross_val_score

cross_validation = cross_val_score(estimator = best_xgb_classifier, X = X_train,y = y_train, cv = 10)

print("Cross validation accuracy of XGBoost model = ", cross_validation)
print("\nCross validation mean accuracy of XGBoost model = ", cross_validation.mean())

"""The mean accuracy value of cross-validation is 96.9%. It means our model can be a little overfitted.

#7. Comparing accuracies of different ML alogorithms

Here, we will comapre the accurraries of different algorithms and find the best model.

> *The table help to compare the models showing that the Logistic Regression and SVM with scaled data give us the highest accuracy of 98.25%*
"""

import pandas as pd
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

models = {
    "Logistic Regression": lr_classifier,
    "Logistic Regression with scaled data": lr_classifier2,
    "SVM": svc_classifier,
    "SVM with scaled data": svc_classifier2,
    "KNN": knn_classifier,
    "KNN with scaled data": knn_classifier2,
    "Decision tree classifier": dt_classifier,
    "Decision tree classifier with scaled data": dt_classifier2,
    "Random Forest": rf_classifier,
    "Random Forest with scaled data": rf_classifier2,
    "XGBoost": xgb_classifier,
    "XGBoost with scaled data": xgb_classifier2 ,
    "XGBoost aftyer hypertuning" : best_xgb_classifier
}

results = []

for name, model in models.items():
    y_pred = model.predict(X_test_sc if 'scaled' in name else X_test) # Use scaled data if 'scaled' in name

    # Calculate metrics
    results.append({
        "Model": name,
        "Accuracy (%)": accuracy_score(y_test, y_pred) * 100,
        "Precision": precision_score(y_test, y_pred, average='weighted'),
        "Recall": recall_score(y_test, y_pred, average='weighted'),
        "F1-Score": f1_score(y_test, y_pred, average='weighted')
        #Remove Inference Time since inference_time is not defined within the loop
    })

# Create styled DataFrame
results_df = pd.DataFrame(results).set_index("Model")

# Style the table with color gradients
def highlight_max(s):
    is_max = s == s.max()
    return ['background-color: yellow' if v else '' for v in is_max]

styled_table = results_df.style \
    .format({
        "Accuracy (%)": "{:.2f}",
        "Precision": "{:.2f}",
        "Recall": "{:.2f}",
        "F1-Score": "{:.2f}"

    }) \
     \
    .set_caption("Model Comparison Results")

# Display in Jupyter Notebook
display(styled_table)

# For saving to file
styled_table.to_excel("model_comparison.xlsx", engine='openpyxl')

"""#6. Save the Machine Learning model


> After completion of the Machine Learning project or building the ML model need to deploy in an application. To deploy the ML model need to save it first. To save the Machine Learning project we can use the pickle or joblib package.


"""

import pickle

# save model
pickle.dump(best_xgb_classifier, open('breast_cancer_detector.pickle', 'wb'))

# load model
breast_cancer_detector_model = pickle.load(open('breast_cancer_detector.pickle', 'rb'))

# predict the output
y_pred = breast_cancer_detector_model.predict(X_test)

# confusion matrix
print('Confusion matrix of XGBoost model: \n',confusion_matrix(y_test, y_pred),'\n')

# show the accuracy
print('Accuracy of XGBoost model = ',accuracy_score(y_test, y_pred))

"""Here, we have saved it as breast_cancer_detector.pickle in our local system but we can change path by passing its address.

# Conclusion

In this project, to get a good accuracy, we trained all supervised classification algorithms such as Logistic Regression, SVM, KNN, Random Forest and XGBoost classifiers. After training with all algorithms, we found that the highest accuracy of 98.2% with logisitic regreesion on the scaled dataset.


> With this, we have completed the Machine learning Project successfully with 98.2% accuracy which is great for ‘Breast Cancer Detection using Machine learning’. Now, we are ready to deploy our ML model in the healthcare project.
"""